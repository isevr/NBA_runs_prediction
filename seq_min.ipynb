{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import visualkeras\n",
    "import tensorflow as tf\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.tree import export_graphviz\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mining(team,opponent):\n",
    "    combined_df = pd.read_csv('gen_sets/'+str(team)+'_runs.csv')\n",
    "    combined_df = combined_df.replace({str(team):'same', str(opponent):'other'}, regex=True)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    encoders = []\n",
    "\n",
    "    for column in combined_df.columns[:-1]:\n",
    "        le = LabelEncoder()\n",
    "        encoders.append(le)\n",
    "        df[column] = le.fit_transform(combined_df[column])\n",
    "\n",
    "    df = pd.concat([df,combined_df.iloc[:,-1]], axis=1)\n",
    "\n",
    "    undersample_len = len(df[df['class'] == 1])\n",
    "\n",
    "    undersample_df = df[df['class'] == 0 ].sample(n=undersample_len, random_state=43)\n",
    "    df = pd.concat([df[df['class'] == 1], undersample_df])\n",
    "\n",
    "    print(df['class'].value_counts())\n",
    "    \n",
    "    run_events = {}\n",
    "    run_max_counts = []\n",
    "\n",
    "    for j, event in zip(range(12,112,11), range(10, 0, -1)):\n",
    "        a = combined_df.iloc[:, -j:-1][combined_df['class'] == 1]\n",
    "\n",
    "        # count occurrences of each row\n",
    "        row_counts = defaultdict(int)\n",
    "        for i in range(len(a)):\n",
    "            row_tuple = tuple(a.iloc[i])\n",
    "            row_counts[row_tuple] += 1\n",
    "\n",
    "        # row with the maximum count\n",
    "        max_count = 0\n",
    "        mc_row = None\n",
    "        for row, count in row_counts.items():\n",
    "            if count > max_count:\n",
    "                max_count = count\n",
    "                mc_row = row\n",
    "\n",
    "        # index of the row \n",
    "        mc_idx = a.apply(lambda row: tuple(row) == mc_row, axis=1).idxmax()\n",
    "\n",
    "\n",
    "        print(f\"Index: {mc_idx}, Max Count: {max_count}\")\n",
    "        run_events[event] = a.iloc[mc_idx]\n",
    "        run_max_counts.append(max_count)\n",
    "        print(f'{combined_df.iloc[mc_idx, -j:-1].to_frame().dropna().T}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:2: DtypeWarning: Columns (104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_df = pd.read_csv('gen_sets/'+str(team)+'_runs.csv')\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1    18471\n",
      "0    18471\n",
      "Name: count, dtype: int64\n",
      "Index: 16388, Max Count: 562\n",
      "          Fouler10\n",
      "16388  fouler_same\n",
      "\n",
      "Index: 16418, Max Count: 108\n",
      "           Rebounder9 ReboundType9     Fouler10\n",
      "16418  rebounder_same    defensive  fouler_same\n",
      "\n",
      "Index: 16446, Max Count: 53\n",
      "            Rebounder8 ReboundType8 ShotDist9       Shooter9     Rebounder10   \n",
      "16446  rebounder_other    defensive       3pt  shooter_other  rebounder_same  \\\n",
      "\n",
      "      ReboundType10  \n",
      "16446     defensive  \n",
      "\n",
      "Index: 16446, Max Count: 30\n",
      "      ShotDist7      Shooter7       Rebounder8 ReboundType8 ShotDist9   \n",
      "16446       3pt  shooter_same  rebounder_other    defensive       3pt  \\\n",
      "\n",
      "            Shooter9     Rebounder10 ReboundType10  \n",
      "16446  shooter_other  rebounder_same     defensive  \n",
      "\n",
      "Index: 16418, Max Count: 16\n",
      "      ShotDist6      Shooter6       Rebounder7 ReboundType7 ShotDist8   \n",
      "16418       3pt  shooter_same  rebounder_other    defensive       3pt  \\\n",
      "\n",
      "            Shooter8      Rebounder9 ReboundType9     Fouler10  \n",
      "16418  shooter_other  rebounder_same    defensive  fouler_same  \n",
      "\n",
      "Index: 16446, Max Count: 5\n",
      "            Rebounder5 ReboundType5 ShotDist6       Shooter6 ShotDist7   \n",
      "16446  rebounder_other    defensive     close  shooter_other       3pt  \\\n",
      "\n",
      "           Shooter7       Rebounder8 ReboundType8 ShotDist9       Shooter9   \n",
      "16446  shooter_same  rebounder_other    defensive       3pt  shooter_other  \\\n",
      "\n",
      "          Rebounder10 ReboundType10  \n",
      "16446  rebounder_same     defensive  \n",
      "\n",
      "Index: 16506, Max Count: 3\n",
      "      ShotDist4       Shooter4      Rebounder5 ReboundType5 ShotDist6   \n",
      "16506       3pt  shooter_other  rebounder_same    defensive       3pt  \\\n",
      "\n",
      "           Shooter6       Rebounder7 ReboundType7       Fouler8   \n",
      "16506  shooter_same  rebounder_other    defensive  fouler_other  \\\n",
      "\n",
      "      FreeThrowShooter9 FreeThrowShooter10  \n",
      "16506          ft_other           ft_other  \n",
      "\n",
      "Index: 17004, Max Count: 3\n",
      "            Rebounder3 ReboundType3 ShotDist4       Shooter4      Rebounder5   \n",
      "17004  rebounder_other    defensive       3pt  shooter_other  rebounder_same  \\\n",
      "\n",
      "      ReboundType5 ShotDist6      Shooter6       Rebounder7 ReboundType7   \n",
      "17004    defensive     close  shooter_same  rebounder_other    defensive  \\\n",
      "\n",
      "      ShotDist8       Shooter8      Rebounder9 ReboundType9     Fouler10  \n",
      "17004       3pt  shooter_other  rebounder_same    defensive  fouler_same  \n",
      "\n",
      "Index: 16549, Max Count: 2\n",
      "      ShotDist2       Shooter2      Rebounder3 ReboundType3 ShotDist4   \n",
      "16549       3pt  shooter_other  rebounder_same    defensive       3pt  \\\n",
      "\n",
      "           Shooter4       Rebounder5 ReboundType5 ShotDist6       Shooter6   \n",
      "16549  shooter_same  rebounder_other    defensive       3pt  shooter_other  \\\n",
      "\n",
      "           Rebounder7 ReboundType7 ShotDist8      Shooter8       Rebounder9   \n",
      "16549  rebounder_same    defensive       3pt  shooter_same  rebounder_other  \\\n",
      "\n",
      "      ReboundType9 ShotDist10      Shooter10  \n",
      "16549    defensive      close  shooter_other  \n",
      "\n",
      "Index: 0, Max Count: 1\n",
      "        Fouler1 FreeThrowShooter2 ShotDist3      Shooter3 ShotDist4   \n",
      "0  fouler_other          ft_other     close  shooter_same       mid  \\\n",
      "\n",
      "        Shooter4      Rebounder5 ReboundType5 ShotDist6      Shooter6   \n",
      "0  shooter_other  rebounder_same    defensive       mid  shooter_same  \\\n",
      "\n",
      "        Rebounder7 ReboundType7 ShotDist8       Shooter8 TurnoverPlayer9   \n",
      "0  rebounder_other    defensive     close  shooter_other  to_player_same  \\\n",
      "\n",
      "  TurnoverPlayer10  \n",
      "0  to_player_other  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_mining('home','away')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n",
      "C:\\Users\\gsevr\\AppData\\Local\\Temp\\ipykernel_88852\\811518203.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column] = le.fit_transform(combined_df[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1    16497\n",
      "0    16497\n",
      "Name: count, dtype: int64\n",
      "Index: 3, Max Count: 4457\n",
      "      Fouler10\n",
      "3  fouler_same\n",
      "\n",
      "Index: 6, Max Count: 978\n",
      "  ShotDist9       Shooter9     Fouler10\n",
      "6     close  shooter_other  fouler_same\n",
      "\n",
      "Index: 17, Max Count: 423\n",
      "         Rebounder8 ReboundType8 ShotDist9       Shooter9     Rebounder10   \n",
      "17  rebounder_other    defensive       3pt  shooter_other  rebounder_same  \\\n",
      "\n",
      "   ReboundType10  \n",
      "17     defensive  \n",
      "\n",
      "Index: 171, Max Count: 194\n",
      "    ShotDist7      Shooter7       Rebounder8 ReboundType8 ShotDist9   \n",
      "171       3pt  shooter_same  rebounder_other    defensive       3pt  \\\n",
      "\n",
      "          Shooter9     Rebounder10 ReboundType10  \n",
      "171  shooter_other  rebounder_same     defensive  \n",
      "\n",
      "Index: 73, Max Count: 54\n",
      "         Rebounder6 ReboundType6       Fouler7 FreeThrowShooter8   \n",
      "73  rebounder_other    defensive  fouler_other          ft_other  \\\n",
      "\n",
      "   FreeThrowShooter9     Fouler10  \n",
      "73          ft_other  fouler_same  \n",
      "\n",
      "Index: 73, Max Count: 24\n",
      "   ShotDist5      Shooter5       Rebounder6 ReboundType6       Fouler7   \n",
      "73       3pt  shooter_same  rebounder_other    defensive  fouler_other  \\\n",
      "\n",
      "   FreeThrowShooter8 FreeThrowShooter9     Fouler10  \n",
      "73          ft_other          ft_other  fouler_same  \n",
      "\n",
      "Index: 153, Max Count: 7\n",
      "         Rebounder4 ReboundType4 ShotDist5      Shooter5       Rebounder6   \n",
      "153  rebounder_same    defensive       3pt  shooter_same  rebounder_other  \\\n",
      "\n",
      "    ReboundType6       Fouler7 FreeThrowShooter8 FreeThrowShooter9   \n",
      "153    defensive  fouler_other          ft_other          ft_other  \\\n",
      "\n",
      "        Fouler10  \n",
      "153  fouler_same  \n",
      "\n",
      "Index: 641, Max Count: 5\n",
      "    ShotDist3       Shooter3      Rebounder4 ReboundType4 ShotDist5   \n",
      "641       3pt  shooter_other  rebounder_same    defensive       3pt  \\\n",
      "\n",
      "         Shooter5       Rebounder6 ReboundType6       Fouler7   \n",
      "641  shooter_same  rebounder_other    defensive  fouler_other  \\\n",
      "\n",
      "    FreeThrowShooter8 FreeThrowShooter9     Fouler10  \n",
      "641          ft_other          ft_other  fouler_same  \n",
      "\n",
      "Index: 3078, Max Count: 3\n",
      "           Fouler2 FreeThrowShooter3       Rebounder4 ReboundType4   \n",
      "3078  fouler_other          ft_other  rebounder_other    offensive  \\\n",
      "\n",
      "     FreeThrowShooter5 ShotDist6      Shooter6       Rebounder7 ReboundType7   \n",
      "3078          ft_other       3pt  shooter_same  rebounder_other    defensive  \\\n",
      "\n",
      "     ShotDist8       Shooter8      Rebounder9 ReboundType9     Fouler10  \n",
      "3078       3pt  shooter_other  rebounder_same    defensive  fouler_same  \n",
      "\n",
      "Index: 572, Max Count: 2\n",
      "    ShotDist1      Shooter1      Rebounder2 ReboundType2 ShotDist3   \n",
      "572       mid  shooter_same  rebounder_same    offensive     close  \\\n",
      "\n",
      "         Shooter3       Rebounder4 ReboundType4       Fouler5   \n",
      "572  shooter_same  rebounder_other    defensive  fouler_other  \\\n",
      "\n",
      "    FreeThrowShooter6 FreeThrowShooter7      Fouler8 FreeThrowShooter9   \n",
      "572          ft_other          ft_other  fouler_same           ft_same  \\\n",
      "\n",
      "        Rebounder10 ReboundType10  \n",
      "572  rebounder_same     offensive  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_mining('away', 'home')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
